{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OrB70kvf9EbR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXghUnRX9G38",
        "outputId": "e18ad2ab-4f4e-4040-e65b-a68d7f9dfcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnQ9gsWL-uAc"
      },
      "outputs": [],
      "source": [
        "players_fpl = pd.read_csv('/content/drive/MyDrive/full2016-2024list.csv')\n",
        "players_2024 = pd.read_csv('/content/drive/MyDrive/merged_gw2024.csv')\n",
        "\n",
        "players_fpl = pd.concat([players_fpl, players_2024], ignore_index=True)\n",
        "\n",
        "players_fpl.head()\n",
        "players_fpl[players_fpl['season_x'].isnull()]\n",
        "\n",
        "players_fpl['season_x'].fillna('2024-25', inplace=True)\n",
        "players_fpl.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aaMdiAZOlJg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# players_fpl.head()\n",
        "players_fpl.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NarBFvRYjYl0"
      },
      "outputs": [],
      "source": [
        "players_fpl[\"name\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKGLUpwOkPBs"
      },
      "outputs": [],
      "source": [
        "\n",
        "players_fpl[\"was_home\"] = players_fpl[\"was_home\"].astype(\"category\").cat.codes\n",
        "players_fpl[\"season_x\"] = players_fpl[\"season_x\"].astype(str).str.split('-').str[0]\n",
        "players_fpl[\"season_x\"] = pd.to_datetime(players_fpl[\"season_x\"], format='%Y')\n",
        "players_fpl.head(129000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WI0KeatPA0e"
      },
      "outputs": [],
      "source": [
        "grouped_players = players_fpl.groupby(\"name\")\n",
        "grouped_players.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHDbUQajFL3U"
      },
      "outputs": [],
      "source": [
        "group = grouped_players.get_group(\"Joško Gvardiol\")\n",
        "group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tZN7ABYOI9Fc"
      },
      "outputs": [],
      "source": [
        "def rolling_averages(group,cols,new_cols):\n",
        "  group = group.sort_values(\"kickoff_time\")\n",
        "  rolling_stats = group[cols].rolling(5, closed='left').mean()\n",
        "  group[new_cols] = rolling_stats\n",
        "  group = group.dropna(subset=new_cols)\n",
        "  return group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtjmb-Yqfaol"
      },
      "outputs": [],
      "source": [
        "cols = [\"assists\",\"bps\",\"clean_sheets\",\"goals_conceded\",\"goals_scored\",\"minutes\",\"own_goals\",\"penalties_missed\",\"red_cards\",\"transfers_in\",\"transfers_out\",\"yellow_cards\",\"GW\",\"total_points\"]\n",
        "new_cols = [f\"{c}_rolling\" for c in cols]\n",
        "new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gdvi2VIlm8d"
      },
      "outputs": [],
      "source": [
        "rolling_averages(group,cols,new_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HQEKUptmk9c"
      },
      "outputs": [],
      "source": [
        "players_rolling = players_fpl.groupby(\"name\").apply(lambda x: rolling_averages(x,cols,new_cols))\n",
        "#creation of frequency of goals and handling infinity vals\n",
        "players_rolling['frequency_goals_rolling'] = players_rolling['minutes_rolling'] / players_rolling['goals_scored_rolling']\n",
        "players_rolling['frequency_goals_rolling'] = players_rolling['frequency_goals_rolling'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "#creation of frequency of assists and handling infinity vals\n",
        "players_rolling['frequency_assists_rolling'] = players_rolling['minutes_rolling'] / players_rolling['assists_rolling']\n",
        "players_rolling['frequency_assists_rolling'] = players_rolling['frequency_assists_rolling'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "players_rolling['bonus_chance_rolling'] = players_rolling['bps_rolling'] * players_rolling['goals_scored_rolling']\n",
        "players_rolling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qA7MhtM7hJx"
      },
      "outputs": [],
      "source": [
        "players_rolling.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmGaMtmCLvTE"
      },
      "outputs": [],
      "source": [
        "players_rolling = players_rolling.droplevel(\"name\")\n",
        "players_rolling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho7th25_n_vj"
      },
      "outputs": [],
      "source": [
        "group = players_rolling.groupby(\"name\").get_group(\"Mohamed Salah\")\n",
        "group = rolling_averages(group,cols,new_cols)\n",
        "group[['GW','total_points_rolling']].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8JUZTs7LdG6"
      },
      "outputs": [],
      "source": [
        "players_rolling.index = range(players_rolling.shape[0])\n",
        "players_rolling.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OBh9k3ACNT4e"
      },
      "outputs": [],
      "source": [
        "players_rolling = players_rolling.drop(['xP', 'starts'], axis=1, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20OxO-o1cvmd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def make_predictions_with_gb_regularized(data, predictors):\n",
        "    train = data[data[\"season_x\"] < '2023-08-01']\n",
        "    test = data[data[\"season_x\"] >= '2023-08-01']\n",
        "    predictors = [col for col in predictors if col != 'total_points_rolling']\n",
        "\n",
        "    X_train = train[predictors]\n",
        "    X_test = test[predictors]\n",
        "    y_train = train['total_points_rolling']\n",
        "    y_test = test['total_points_rolling']\n",
        "\n",
        "    #GPT ftw\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=500,       # Number of boosting stages\n",
        "        learning_rate=0.01,     # Shrinkage parameter\n",
        "        max_depth=2,            # Maximum depth of each tree\n",
        "        min_samples_split=12,   # Minimum number of samples required to split a node\n",
        "        min_samples_leaf=8,    # Minimum number of samples required in a leaf node\n",
        "        subsample=0.8,          # Fraction of samples to be used for fitting the individual base learners\n",
        "        random_state=42      # Ensuring reproducibility\n",
        "\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # eval metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    display(f'Regularized Model Results:')\n",
        "    print(f'MSE: {mse}')\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'R² Score: {r2}')\n",
        "\n",
        "    # specific player stats\n",
        "    player_name = \"João Pedro Junqueira de Jesus\"\n",
        "    player_test_data = test[test[\"name\"] == player_name]\n",
        "\n",
        "    if player_test_data.empty:\n",
        "        print(\"No data available for the specified player.\")\n",
        "        return\n",
        "\n",
        "    player_test_data = player_test_data.sort_values(by=\"GW\", ascending=False)\n",
        "    last_10_matches = player_test_data.head(20)\n",
        "\n",
        "    last_10_indices = last_10_matches.index\n",
        "    player_predictions = y_pred[test.index.get_indexer(last_10_indices)]\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Gameweek\": last_10_matches[\"GW\"].values,\n",
        "        \"Actual Points\": last_10_matches[\"total_points_rolling\"].values,\n",
        "        \"Predicted Points\": player_predictions\n",
        "    })\n",
        "\n",
        "    print(\"\\nJoão Pedro Junqueira de Jesus' Last 10 Matches:\")\n",
        "    print(results_df)\n",
        "\n",
        "    #feature importances\n",
        "    importances = model.feature_importances_\n",
        "\n",
        "    feature_importances = pd.DataFrame({\n",
        "    'Feature': predictors,\n",
        "    'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(feature_importances)\n",
        "\n",
        "    test['predicted_points'] = y_pred\n",
        "\n",
        "    # top 10 unik players by position\n",
        "    positions = test['position'].unique()\n",
        "    top_players_by_position = {}\n",
        "\n",
        "    for position in positions:\n",
        "        # Filter the data by position\n",
        "        position_data = test[test['position'] == position]\n",
        "\n",
        "        # Sort by predicted points in descending order\n",
        "        position_data = position_data.sort_values(by='predicted_points', ascending=False)\n",
        "\n",
        "        # Drop duplicates to get unique players\n",
        "        position_data_unique = position_data.drop_duplicates(subset=['name'], keep='first')\n",
        "\n",
        "        # Get the top 10 unique players\n",
        "        top_10 = position_data_unique.head(20)\n",
        "        top_players_by_position[position] = top_10[['name', 'predicted_points', 'value']]\n",
        "\n",
        "    # top 10 unik player position wise\n",
        "    for position, df in top_players_by_position.items():\n",
        "        print(f\"\\nTop 10 Players for Position: {position}\")\n",
        "        print(df)\n",
        "\n",
        "# Call func\n",
        "exclude_columns = ['season_x', 'name', 'position', 'team_x', 'kickoff_time', 'opp_team_name', 'total_points_rolling','penalties_missed_rolling','yellow_cards','was_home','assists','threat','bonus','minutes','bps','clean_sheets','elements','goals_conceded','goals_scored','ict_index','opponent_team','team_h_score','own_goals','penalties_missed','penalties_saved','red_cards','round','team_a_score','GW_rolling','GW','element','influence','transfers_out_rolling','creativity','fixture','transfers_out','total_points','transfers_balance','selected','own_goals_rolling']\n",
        "predictors = [col for col in players_rolling.columns if col not in exclude_columns]\n",
        "make_predictions_with_gb_regularized(players_rolling, predictors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR_N5f2KsSE7"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def make_predictions_with_gb_pca(data, predictors, n_components=0.95):\n",
        "\n",
        "    train = data[data[\"season_x\"] < '2023-01-01']\n",
        "    test = data[data[\"season_x\"] >= '2023-01-01']\n",
        "    predictors = [col for col in predictors if col != 'total_points_rolling']\n",
        "\n",
        "    X_train = train[predictors]\n",
        "    X_test = test[predictors]\n",
        "    y_train = train['total_points_rolling']\n",
        "    y_test = test['total_points_rolling']\n",
        "\n",
        "    #standard scaler for pca\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # dim reduction\n",
        "    pca = PCA(n_components=n_components)\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    # explained variance ratio\n",
        "    print(\"\\nExplained Variance Ratio by Principal Component:\")\n",
        "    explained_variance_ratio = pca.explained_variance_ratio_\n",
        "    for i, var_ratio in enumerate(explained_variance_ratio):\n",
        "        print(f\"PC{i+1}: {var_ratio:.4f}\")\n",
        "\n",
        "    cumulative_variance_ratio = pca.explained_variance_ratio_.cumsum()\n",
        "    print(\"\\nCumulative Explained Variance Ratio by Principal Component:\")\n",
        "    for i, cum_var_ratio in enumerate(cumulative_variance_ratio):\n",
        "        print(f\"PC{i+1}: {cum_var_ratio:.4f}\")\n",
        "\n",
        "\n",
        "    # GPT ftw\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=500,       # Number of boosting stages\n",
        "        learning_rate=0.01,     # Shrinkage parameter\n",
        "        max_depth=2,            # Maximum depth of each tree\n",
        "        min_samples_split=10,   # Minimum number of samples required to split a node\n",
        "        min_samples_leaf=5,     # Minimum number of samples required in a leaf node\n",
        "        subsample=0.8,          # Fraction of samples to be used for fitting the individual base learners\n",
        "        random_state=42         # Ensuring reproducibility\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "\n",
        "    # eval metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f'Regularized Model with PCA Results:')\n",
        "    print(f'MSE: {mse}')\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'R² Score: {r2}')\n",
        "\n",
        "    # specfic player stats\n",
        "    player_name = \"Mohamed Salah\"\n",
        "    player_test_data = test[test[\"name\"] == player_name]\n",
        "\n",
        "    if player_test_data.empty:\n",
        "        print(\"No data available for the specified player.\")\n",
        "        return\n",
        "\n",
        "    player_test_data = player_test_data.sort_values(by=\"GW\", ascending=False)\n",
        "    last_10_matches = player_test_data.head(10)\n",
        "\n",
        "    last_10_indices = last_10_matches.index\n",
        "    player_predictions = y_pred[test.index.get_indexer(last_10_indices)]\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Gameweek\": last_10_matches[\"GW\"].values,\n",
        "        \"Actual Points\": last_10_matches[\"total_points_rolling\"].values,\n",
        "        \"Predicted Points\": player_predictions\n",
        "    })\n",
        "\n",
        "    print(\"\\nMohamed Salah's Last 10 Matches:\")\n",
        "    print(results_df)\n",
        "\n",
        "    #feaure improtance\n",
        "    importances = model.feature_importances_\n",
        "    feature_names = [f\"PC{i+1}\" for i in range(X_train_pca.shape[1])]\n",
        "    feature_importances = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(feature_importances)\n",
        "\n",
        "    test['predicted_points'] = y_pred\n",
        "\n",
        "    # top 10 unik players by pos\n",
        "    positions = test['position'].unique()\n",
        "    top_players_by_position = {}\n",
        "\n",
        "    for position in positions:\n",
        "        # Filter the data by position\n",
        "        position_data = test[test['position'] == position]\n",
        "\n",
        "        # Sort by predicted points in descending order\n",
        "        position_data = position_data.sort_values(by='predicted_points', ascending=False)\n",
        "\n",
        "        # Drop duplicates to get unique players\n",
        "        position_data_unique = position_data.drop_duplicates(subset=['name'], keep='first')\n",
        "\n",
        "        # Get the top 10 unique players\n",
        "        top_10 = position_data_unique.head(10)\n",
        "\n",
        "        # Store the result in a dictionary\n",
        "        top_players_by_position[position] = top_10[['name', 'predicted_points', 'value']]\n",
        "\n",
        "    #top 10 unik player pos wise\n",
        "    for position, df in top_players_by_position.items():\n",
        "        print(f\"\\nTop 10 Players for Position: {position}\")\n",
        "        print(df)\n",
        "\n",
        "# main func\n",
        "exclude_columns = ['season_x', 'name', 'position', 'team_x','team', 'kickoff_time', 'opp_team_name', 'total_points_rolling', 'penalties_missed_rolling', 'yellow_cards', 'was_home', 'assists', 'threat', 'bonus', 'minutes', 'bps', 'clean_sheets', 'elements', 'goals_conceded', 'goals_scored', 'ict_index', 'opponent_team', 'team_h_score', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'round', 'team_a_score', 'GW_rolling', 'GW', 'element', 'influence', 'transfers_out_rolling', 'creativity', 'fixture', 'transfers_out', 'total_points', 'transfers_balance', 'selected', 'own_goals_rolling','goals_conceded_rolling','red_cards_rolling','yellow_cards_rolling']\n",
        "predictors = [col for col in players_rolling.columns if col not in exclude_columns]\n",
        "make_predictions_with_gb_pca(players_rolling, predictors, n_components=0.95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj93PQCC9H-2"
      },
      "outputs": [],
      "source": [
        "#GPT FTW(best team)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def make_predictions_with_gb_pca(data, predictors, n_components=0.95):\n",
        "    # Step 1: Split the data into train and test\n",
        "    train = data[data[\"season_x\"] < '2023-08-01']\n",
        "    test = data[data[\"season_x\"] >= '2023-08-01']\n",
        "\n",
        "    # Ensure 'total_points_rolling' is not in predictors\n",
        "    predictors = [col for col in predictors if col != 'total_points_rolling']\n",
        "\n",
        "    X_train = train[predictors]\n",
        "    X_test = test[predictors]\n",
        "    y_train = train['total_points_rolling']\n",
        "    y_test = test['total_points_rolling']\n",
        "\n",
        "    # Step 2: Standardize the features before PCA\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Step 3: Apply PCA to reduce dimensionality\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    # Step 4: Apply Gradient Boosting with Regularization\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=500,       # Number of boosting stages\n",
        "        learning_rate=0.01,     # Shrinkage parameter\n",
        "        max_depth=2,            # Maximum depth of each tree\n",
        "        min_samples_split=12,   # Minimum number of samples required to split a node\n",
        "        min_samples_leaf=8,     # Minimum number of samples required in a leaf node\n",
        "        subsample=0.8,          # Fraction of samples to be used for fitting the individual base learners\n",
        "        random_state=42,\n",
        "                            # Ensuring reproducibility\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "\n",
        "    # Step 5: Evaluate the model\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f'Regularized Model with PCA Results:')\n",
        "    print(f'MSE: {mse}')\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'R² Score: {r2}')\n",
        "\n",
        "    # Step 6: Add the predictions to the test dataset\n",
        "    test['predicted_points'] = y_pred\n",
        "\n",
        "    return test  # Return the test dataset with predictions\n",
        "\n",
        "def select_best_team_with_key_players(data, unavailable_players, key_players, budget=100):\n",
        "    num_goalkeepers = 2\n",
        "    num_defenders = 5\n",
        "    num_midfielders = 5\n",
        "    num_forwards = 3\n",
        "\n",
        "    # Adjust player values (divide by 10 as specified)\n",
        "    data['adjusted_value'] = data['value'] / 10\n",
        "\n",
        "    # Step 2: Filter out unavailable players from the data\n",
        "    next_gw_data = data.dropna(subset=['predicted_points'])\n",
        "    next_gw_data = next_gw_data[~next_gw_data['name'].isin(unavailable_players)]\n",
        "\n",
        "    # Separate key players\n",
        "    key_players_data = next_gw_data[next_gw_data['name'].isin(key_players)]\n",
        "    non_key_players_data = next_gw_data[~next_gw_data['name'].isin(key_players)]\n",
        "\n",
        "    # Separate non-key players by position\n",
        "    goalkeepers = non_key_players_data[non_key_players_data['position'] == 'GK'].copy()\n",
        "    defenders = non_key_players_data[non_key_players_data['position'] == 'DEF'].copy()\n",
        "    midfielders = non_key_players_data[non_key_players_data['position'] == 'MID'].copy()\n",
        "    forwards = non_key_players_data[non_key_players_data['position'] == 'FWD'].copy()\n",
        "\n",
        "    def select_players(position_data, num_players, budget):\n",
        "        position_data['points_per_value'] = position_data['predicted_points'] / position_data['adjusted_value']\n",
        "        position_data = position_data.sort_values(by='points_per_value', ascending=False)\n",
        "        costs = position_data['adjusted_value'].values\n",
        "        points = position_data['predicted_points'].values\n",
        "\n",
        "        c = -points\n",
        "        A_eq = []\n",
        "        b_eq = []\n",
        "        if len(position_data) >= num_players:\n",
        "            A_eq.append([1] * len(costs))\n",
        "            b_eq.append(num_players)\n",
        "        else:\n",
        "            return pd.DataFrame()  # Not enough players to fill the required positions\n",
        "\n",
        "        A_ub = [costs]\n",
        "        b_ub = [budget]\n",
        "\n",
        "        bounds = [(0, 1) for _ in range(len(costs))]\n",
        "\n",
        "        result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
        "\n",
        "        if result.success:\n",
        "            selected_indices = [i for i, x in enumerate(result.x) if x > 0.5]\n",
        "            selected_data = position_data.iloc[selected_indices]\n",
        "            return selected_data\n",
        "        else:\n",
        "            print(f\"No feasible solution found for position. Consider increasing budget or relaxing constraints.\")\n",
        "            return pd.DataFrame()  # Return empty DataFrame if no solution is found\n",
        "\n",
        "    # Select players for each position\n",
        "    selected_players = []\n",
        "\n",
        "    selected_gk = select_players(goalkeepers, num_goalkeepers, budget)\n",
        "    selected_players.append(selected_gk)\n",
        "\n",
        "    remaining_budget = budget - selected_gk['adjusted_value'].sum()\n",
        "    selected_def = select_players(defenders, num_defenders, remaining_budget)\n",
        "    selected_players.append(selected_def)\n",
        "\n",
        "    remaining_budget = budget - selected_gk['adjusted_value'].sum() - selected_def['adjusted_value'].sum()\n",
        "    selected_mid = select_players(midfielders, num_midfielders, remaining_budget)\n",
        "    selected_players.append(selected_mid)\n",
        "\n",
        "    remaining_budget = budget - selected_gk['adjusted_value'].sum() - selected_def['adjusted_value'].sum() - selected_mid['adjusted_value'].sum()\n",
        "    selected_fwd = select_players(forwards, num_forwards, remaining_budget)\n",
        "    selected_players.append(selected_fwd)\n",
        "\n",
        "    # Concatenate all selected non-key players\n",
        "    all_selected_players = pd.concat(selected_players)\n",
        "\n",
        "    # Add the key players\n",
        "    all_selected_players = pd.concat([all_selected_players, key_players_data])\n",
        "\n",
        "    # Ensure all selected players are unique\n",
        "    all_selected_players = all_selected_players.drop_duplicates(subset='name')\n",
        "\n",
        "    # Adjust for budget, prioritizing key players\n",
        "    tolerance = 1.0\n",
        "    total_value = all_selected_players['adjusted_value'].sum()\n",
        "    while total_value > budget + tolerance and len(all_selected_players) > 0:\n",
        "        non_key_players = all_selected_players[~all_selected_players['name'].isin(key_players)]\n",
        "        if len(non_key_players) > 0:\n",
        "            non_key_players = non_key_players.sort_values(by='points_per_value', ascending=True)\n",
        "            all_selected_players = all_selected_players[~all_selected_players['name'].isin([non_key_players.iloc[0]['name']])]\n",
        "        else:\n",
        "            print(\"Unable to adjust the team within the budget without removing key players.\")\n",
        "            break\n",
        "        total_value = all_selected_players['adjusted_value'].sum()\n",
        "\n",
        "    # Ensure exactly 15 players\n",
        "    if len(all_selected_players) < 15:\n",
        "        print(f\"Warning: Selected players are fewer than 15. Adding more players if available.\")\n",
        "        remaining_players = next_gw_data[~next_gw_data['name'].isin(all_selected_players['name'])]\n",
        "        additional_players = remaining_players.sample(n=15 - len(all_selected_players))\n",
        "        all_selected_players = pd.concat([all_selected_players, additional_players])\n",
        "\n",
        "    total_points = all_selected_players['predicted_points'].sum()\n",
        "\n",
        "    print(f\"Selected Squad:\\n{all_selected_players[['name', 'position', 'adjusted_value', 'predicted_points']]}\")\n",
        "    print(f\"\\nTotal Value: {total_value}\")\n",
        "    print(f\"Total Predicted Points: {total_points}\")\n",
        "\n",
        "    return all_selected_players\n",
        "\n",
        "# Call the function with regularization and PCA FIRST\n",
        "exclude_columns = ['season_x', 'name', 'position', 'team_x','team', 'kickoff_time', 'opp_team_name', 'total_points_rolling', 'penalties_missed_rolling', 'yellow_cards', 'was_home', 'assists', 'threat', 'bonus', 'minutes', 'bps', 'clean_sheets', 'elements', 'goals_conceded', 'goals_scored', 'ict_index', 'opponent_team', 'team_h_score', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'round', 'team_a_score', 'GW_rolling', 'GW', 'element', 'influence', 'transfers_out_rolling', 'creativity', 'fixture', 'transfers_out', 'total_points', 'transfers_balance', 'selected', 'own_goals_rolling','goals_conceded_rolling','red_cards_rolling','yellow_cards_rolling']\n",
        "predictors = [col for col in players_rolling.columns if col not in exclude_columns]\n",
        "predicted_data = make_predictions_with_gb_pca(players_rolling, predictors, n_components=0.95)\n",
        "unavailable_players = [\n",
        "        \"Kieran Tierney\", \"Takehiro Tomiyasu\", \"Fabio Ferreira Vieira\", \"Enes Unal\",\n",
        "        \"Tyler Adams\", \"David Brooks\", \"Boubacar Kamara\", \"Tyrone Mings\",\n",
        "        \"Joshua Dasilva\", \"Aaron Hickey\", \"Rico Henry\", \"Igor Thiago Nascimento Rodrigues\",\n",
        "        \"Solomon March\", \"Bart Verbruggen\", \"Reece James\", \"Matheus Franca de Oliveira\",\n",
        "        \"Youssef Ramalho Chermiti\", \"Nathan Patterson\", \"Jarrad Branthwaite\",\n",
        "        \"James Garner\", \"Seamus Coleman\", \"Ashley Young\", \"James Tarkowski\",\n",
        "        \"Bamidele Alli\", \"Harry Clarke\", \"George Hirst\", \"Nathan Broadhead\",\n",
        "        \"Wesley Burns\", \"Kalvin Phillips\", \"Janoi Donacien\", \"Patson Daka\",\n",
        "        \"Conor Coady\", \"Oscar Bobb\", \"Leny Yoro\", \"Tyrell Malacia\", \"Will Fish\",\n",
        "        \"Victor Lindelof\", \"Luke Shaw\", \"Rasmus Winther Hojlund\", \"Sven Botman\",\n",
        "        \"Jamaal Lascelles\", \"Lewis Miley\", \"Fabian Schar\", \"Sandro Tonali\",\n",
        "        \"Callum Wilson\", \"Danilo dos Santos de Oliveira\", \"Gavin Bazunu\",\n",
        "        \"Juan Larios\", \"Dominic Solanke\", \"Rodrigo Bentancur\", \"Nelson Semedo\",\n",
        "        \"Enso Gonzalez Medina\", \"Leon Chiwone\", \"Sasa Kalajdzic\",\"Jarell Quansah\"\n",
        "]\n",
        "\n",
        "# Usage example\n",
        "key_players = ['Erling Haaland']  # Specify key players like Haaland\n",
        "best_team = select_best_team_with_key_players(predicted_data, unavailable_players, key_players)\n",
        "best_team\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT ftw again but with pca(best team)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def make_predictions_with_gb_pca(data, predictors, n_components=0.95):\n",
        "    # Step 1: Split the data into train and test\n",
        "    train = data[data[\"season_x\"] < '2023-08-01']\n",
        "    test = data[data[\"season_x\"] >= '2023-08-01']\n",
        "\n",
        "    # Ensure 'total_points_rolling' is not in predictors\n",
        "    predictors = [col for col in predictors if col != 'total_points_rolling']\n",
        "\n",
        "    X_train = train[predictors]\n",
        "    X_test = test[predictors]\n",
        "    y_train = train['total_points_rolling']\n",
        "    y_test = test['total_points_rolling']\n",
        "\n",
        "    # Step 2: Standardize the features before PCA\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Step 3: Apply PCA to reduce dimensionality\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    # Step 4: Apply Gradient Boosting with Regularization\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=500,       # Number of boosting stages\n",
        "        learning_rate=0.01,     # Shrinkage parameter\n",
        "        max_depth=2,            # Maximum depth of each tree\n",
        "        min_samples_split=12,   # Minimum number of samples required to split a node\n",
        "        min_samples_leaf=8,     # Minimum number of samples required in a leaf node\n",
        "        subsample=0.8,          # Fraction of samples to be used for fitting the individual base learners\n",
        "        random_state=42,\n",
        "                            # Ensuring reproducibility\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "\n",
        "    # Step 5: Evaluate the model\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f'Regularized Model with PCA Results:')\n",
        "    print(f'MSE: {mse}')\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'R² Score: {r2}')\n",
        "\n",
        "    # Step 6: Add the predictions to the test dataset\n",
        "    test['predicted_points'] = y_pred\n",
        "\n",
        "    return test  # Return the test dataset with predictions\n",
        "\n",
        "def select_best_team(data, unavailable_players, budget=100, min_predicted_points=4):\n",
        "    num_goalkeepers = 2\n",
        "    num_defenders = 5\n",
        "    num_midfielders = 5\n",
        "    num_forwards = 3\n",
        "\n",
        "    # Adjust player values (divide by 10 to match budget scale)\n",
        "    data['adjusted_value'] = data['value'] / 10\n",
        "\n",
        "    # Filter out unavailable players\n",
        "    available_data = data[~data['name'].isin(unavailable_players)]\n",
        "\n",
        "    # Filter out players without predicted points and below the minimum threshold\n",
        "    next_gw_data = available_data.dropna(subset=['predicted_points'])\n",
        "    next_gw_data = next_gw_data[next_gw_data['predicted_points'] >= min_predicted_points]\n",
        "\n",
        "    # Weighting for midfielders and forwards\n",
        "    next_gw_data['weighted_score'] = (\n",
        "        0.5 * next_gw_data['predicted_points'] +\n",
        "        0.25 * next_gw_data['frequency_goals_rolling'] +\n",
        "        0.25 * next_gw_data['frequency_assists_rolling']\n",
        "    )\n",
        "\n",
        "    # Separate players by their position\n",
        "    goalkeepers = next_gw_data[next_gw_data['position'] == 'GK'].copy()\n",
        "    defenders = next_gw_data[next_gw_data['position'] == 'DEF'].copy()\n",
        "    midfielders = next_gw_data[next_gw_data['position'] == 'MID'].copy()\n",
        "    forwards = next_gw_data[next_gw_data['position'] == 'FWD'].copy()\n",
        "\n",
        "    # Function to select players using linear programming\n",
        "    def select_players(position_data, num_players, use_weighted_score=False):\n",
        "        if len(position_data) < num_players:\n",
        "            print(f\"Not enough players available for position, required: {num_players}, available: {len(position_data)}\")\n",
        "            return pd.DataFrame()  # Return an empty DataFrame if not enough players are available\n",
        "\n",
        "        costs = position_data['adjusted_value'].values  # Adjusted values as costs\n",
        "        points = position_data['weighted_score'].values if use_weighted_score else position_data['predicted_points'].values\n",
        "\n",
        "        c = -points  # Objective is to maximize points (minimize -points)\n",
        "        A_eq = [[1] * len(costs)]  # Ensures the right number of players are selected\n",
        "        b_eq = [num_players]\n",
        "\n",
        "        A_ub = [costs]  # Constraint to stay within budget\n",
        "        b_ub = [budget]\n",
        "\n",
        "        bounds = [(0, 1) for _ in range(len(costs))]  # Player can either be selected (1) or not (0)\n",
        "\n",
        "        # Solve the linear programming problem\n",
        "        result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
        "\n",
        "        if result.success:\n",
        "            selected_indices = [i for i, x in enumerate(result.x) if x > 0.5]  # Get indices of selected players\n",
        "            selected_data = position_data.iloc[selected_indices]\n",
        "            return selected_data\n",
        "        else:\n",
        "            print(f\"No feasible solution found for position. Consider increasing budget or relaxing constraints.\")\n",
        "            return pd.DataFrame()  # Return empty DataFrame if no solution is found\n",
        "\n",
        "    # Initialize an empty list to store selected players\n",
        "    selected_players = []\n",
        "\n",
        "    # Select players for each position\n",
        "    selected_gk = select_players(goalkeepers, num_goalkeepers)\n",
        "    selected_players.append(selected_gk)\n",
        "\n",
        "    selected_def = select_players(defenders, num_defenders)\n",
        "    selected_players.append(selected_def)\n",
        "\n",
        "    # Use weighted score for midfielders and forwards\n",
        "    selected_mid = select_players(midfielders, num_midfielders, use_weighted_score=True)\n",
        "    selected_players.append(selected_mid)\n",
        "\n",
        "    selected_fwd = select_players(forwards, num_forwards, use_weighted_score=True)\n",
        "    selected_players.append(selected_fwd)\n",
        "\n",
        "    # Concatenate all selected players into one DataFrame\n",
        "    all_selected_players = pd.concat(selected_players)\n",
        "\n",
        "    # Ensure all selected players are unique (no duplicates)\n",
        "    all_selected_players = all_selected_players.drop_duplicates(subset='name')\n",
        "\n",
        "    # Ensure exactly 15 players and adjust the total value within the budget\n",
        "    if len(all_selected_players) < 15:\n",
        "        remaining_players = next_gw_data[~next_gw_data['name'].isin(all_selected_players['name'])]\n",
        "        additional_players = remaining_players.sample(n=15 - len(all_selected_players))\n",
        "        all_selected_players = pd.concat([all_selected_players, additional_players])\n",
        "\n",
        "    # Adjust the team to fit within the budget if needed\n",
        "    while True:\n",
        "        total_value = all_selected_players['adjusted_value'].sum()\n",
        "        if total_value <= budget:\n",
        "            break\n",
        "        # Remove the most expensive player\n",
        "        all_selected_players = all_selected_players.sort_values(by='adjusted_value', ascending=False)\n",
        "        all_selected_players = all_selected_players.iloc[:-1]  # Remove the most expensive player\n",
        "\n",
        "    # If fewer than 15 players, add additional players\n",
        "    while len(all_selected_players) < 15:\n",
        "        remaining_players = next_gw_data[~next_gw_data['name'].isin(all_selected_players['name'])]\n",
        "        additional_players = remaining_players.sample(n=15 - len(all_selected_players))\n",
        "        all_selected_players = pd.concat([all_selected_players, additional_players])\n",
        "\n",
        "    # Calculate total predicted points for the final squad\n",
        "    total_points = all_selected_players['predicted_points'].sum()\n",
        "\n",
        "    print(f\"\\nTotal Value: {all_selected_players['adjusted_value'].sum()}\")\n",
        "    print(f\"Total Predicted Points: {total_points}\")\n",
        "    print(f\"Final selected players count: {len(all_selected_players)}\")\n",
        "\n",
        "    return all_selected_players\n",
        "\n",
        "# Call the function with regularization and PCA FIRST\n",
        "exclude_columns = ['season_x', 'name', 'position', 'team_x','team', 'kickoff_time', 'opp_team_name', 'total_points_rolling', 'penalties_missed_rolling', 'yellow_cards', 'was_home', 'assists', 'threat', 'bonus', 'minutes', 'bps', 'clean_sheets', 'elements', 'goals_conceded', 'goals_scored', 'ict_index', 'opponent_team', 'team_h_score', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'round', 'team_a_score', 'GW_rolling', 'GW', 'element', 'influence', 'transfers_out_rolling', 'creativity', 'fixture', 'transfers_out', 'total_points', 'transfers_balance', 'selected', 'own_goals_rolling','goals_conceded_rolling','red_cards_rolling','yellow_cards_rolling']\n",
        "predictors = [col for col in players_rolling.columns if col not in exclude_columns]\n",
        "predicted_data = make_predictions_with_gb_pca(players_rolling, predictors, n_components=0.95)\n",
        "unavailable_players = [\n",
        "        \"Kieran Tierney\", \"Takehiro Tomiyasu\", \"Fabio Ferreira Vieira\", \"Enes Unal\",\n",
        "        \"Tyler Adams\", \"David Brooks\", \"Boubacar Kamara\", \"Tyrone Mings\",\n",
        "        \"Joshua Dasilva\", \"Aaron Hickey\", \"Rico Henry\", \"Igor Thiago Nascimento Rodrigues\",\n",
        "        \"Solomon March\", \"Bart Verbruggen\", \"Reece James\", \"Matheus Franca de Oliveira\",\n",
        "        \"Youssef Ramalho Chermiti\", \"Nathan Patterson\", \"Jarrad Branthwaite\",\n",
        "        \"James Garner\", \"Seamus Coleman\", \"Ashley Young\", \"James Tarkowski\",\n",
        "        \"Bamidele Alli\", \"Harry Clarke\", \"George Hirst\", \"Nathan Broadhead\",\n",
        "        \"Wesley Burns\", \"Kalvin Phillips\", \"Janoi Donacien\", \"Patson Daka\",\n",
        "        \"Conor Coady\", \"Oscar Bobb\", \"Leny Yoro\", \"Tyrell Malacia\", \"Will Fish\",\n",
        "        \"Victor Lindelof\", \"Luke Shaw\", \"Rasmus Winther Hojlund\", \"Sven Botman\",\n",
        "        \"Jamaal Lascelles\", \"Lewis Miley\", \"Fabian Schar\", \"Sandro Tonali\",\n",
        "        \"Callum Wilson\", \"Danilo dos Santos de Oliveira\", \"Gavin Bazunu\",\n",
        "        \"Juan Larios\", \"Dominic Solanke\", \"Rodrigo Bentancur\", \"Nelson Semedo\",\n",
        "        \"Enso Gonzalez Medina\", \"Leon Chiwone\", \"Sasa Kalajdzic\",\"Jarell Quansah\"\n",
        "]\n",
        "\n",
        "# Usage example\n",
        "key_players = ['Erling Haaland']  # Specify key players like Haaland\n",
        "best_team = select_best_team_with_key_players(predicted_data, unavailable_players, key_players)\n",
        "best_team\n"
      ],
      "metadata": {
        "id": "kTwwlVr0JQxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clown ahh code but i tried\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "def make_predictions_with_gb_pca(data, predictors, n_components=0.95):\n",
        "\n",
        "    train = data[data[\"season_x\"] < '2023-08-01']\n",
        "    test = data[data[\"season_x\"] >= '2023-08-01']\n",
        "\n",
        "    # total pts rollin nikaal diya\n",
        "    predictors = [col for col in predictors if col != 'total_points_rolling']\n",
        "\n",
        "    X_train = train[predictors]\n",
        "    X_test = test[predictors]\n",
        "    y_train = train['total_points_rolling']\n",
        "    y_test = test['total_points_rolling']\n",
        "\n",
        "    # standard scaler for pca\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # dim reduction\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    # GPT ftw\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=500,       # Number of boosting stages\n",
        "        learning_rate=0.01,     # Shrinkage parameter\n",
        "        max_depth=2,            # Maximum depth of each tree\n",
        "        min_samples_split=12,   # Minimum number of samples required to split a node\n",
        "        min_samples_leaf=8,     # Minimum number of samples required in a leaf node\n",
        "        subsample=0.8,          # Fraction of samples to be used for fitting the individual base learners\n",
        "        random_state=42,\n",
        "                            # Ensuring reproducibility\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "\n",
        "    #eval metric\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f'Regularized Model with PCA Results:')\n",
        "    print(f'MSE: {mse}')\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'R² Score: {r2}')\n",
        "\n",
        "    #add pred to test\n",
        "    test['predicted_points'] = y_pred\n",
        "    return test\n",
        "\n",
        "def greedy_select_team(data, unavailable_players, budget=100):\n",
        "    num_goalkeepers = 2\n",
        "    num_defenders = 5\n",
        "    num_midfielders = 5\n",
        "    num_forwards = 3\n",
        "\n",
        "    data['adjusted_value'] = data['value'] / 10\n",
        "\n",
        "    # unavailable players\n",
        "    available_data = data[~data['name'].isin(unavailable_players)]\n",
        "    next_gw_data = available_data.dropna(subset=['predicted_points'])\n",
        "\n",
        "    # weight calc karo\n",
        "    next_gw_data['weighted_score'] = (\n",
        "        0.5 * next_gw_data['predicted_points'] +\n",
        "        0.25 * next_gw_data['frequency_goals_rolling'] +\n",
        "        0.25 * next_gw_data['frequency_assists_rolling']\n",
        "    )\n",
        "\n",
        "    # score to cost ratio calc karo\n",
        "    next_gw_data['score_to_cost'] = next_gw_data['weighted_score'] / next_gw_data['adjusted_value']\n",
        "    next_gw_data = next_gw_data.sort_values(by='score_to_cost', ascending=False)\n",
        "\n",
        "\n",
        "    selected_players = pd.DataFrame(columns=next_gw_data.columns)\n",
        "\n",
        "    # position wise player select karo\n",
        "    def select_position_players(position_data, num_players):\n",
        "        nonlocal budget, selected_players\n",
        "\n",
        "        for _, player in position_data.iterrows():\n",
        "            if len(selected_players[selected_players['position'] == player['position']]) < num_players and player['adjusted_value'] <= budget:\n",
        "                selected_players = pd.concat([selected_players, player.to_frame().T])\n",
        "                budget -= player['adjusted_value']\n",
        "\n",
        "    # select player by position\n",
        "    select_position_players(next_gw_data[next_gw_data['position'] == 'GK'], num_goalkeepers)\n",
        "    select_position_players(next_gw_data[next_gw_data['position'] == 'DEF'], num_defenders)\n",
        "    select_position_players(next_gw_data[next_gw_data['position'] == 'MID'], num_midfielders)\n",
        "    select_position_players(next_gw_data[next_gw_data['position'] == 'FWD'], num_forwards)\n",
        "\n",
        "    # final squad total point\n",
        "    total_points = selected_players['predicted_points'].sum()\n",
        "\n",
        "    print(f\"\\nTotal Value: {selected_players['adjusted_value'].sum()}\")\n",
        "    print(f\"Total Predicted Points: {total_points}\")\n",
        "    print(f\"Finalised Squad: {len(selected_players)}\")\n",
        "\n",
        "    return selected_players\n",
        "\n",
        "\n",
        "# Calling func with Pca\n",
        "exclude_columns = ['season_x', 'name', 'position', 'team_x','team', 'kickoff_time', 'opp_team_name', 'total_points_rolling', 'penalties_missed_rolling', 'yellow_cards', 'was_home', 'assists', 'threat', 'bonus', 'minutes', 'bps', 'clean_sheets', 'elements', 'goals_conceded', 'goals_scored', 'ict_index', 'opponent_team', 'team_h_score', 'own_goals', 'penalties_missed', 'penalties_saved', 'red_cards', 'round', 'team_a_score', 'GW_rolling', 'GW', 'element', 'influence', 'transfers_out_rolling', 'creativity', 'fixture', 'transfers_out', 'total_points', 'transfers_balance', 'selected', 'own_goals_rolling','goals_conceded_rolling','red_cards_rolling','yellow_cards_rolling']\n",
        "predictors = [col for col in players_rolling.columns if col not in exclude_columns]\n",
        "predicted_data = make_predictions_with_gb_pca(players_rolling, predictors, n_components=0.95)\n",
        "unavailable_players = [\n",
        "        \"Kieran Tierney\", \"Takehiro Tomiyasu\", \"Fabio Ferreira Vieira\", \"Enes Unal\",\n",
        "        \"Tyler Adams\", \"David Brooks\", \"Boubacar Kamara\", \"Tyrone Mings\",\n",
        "        \"Joshua Dasilva\", \"Aaron Hickey\", \"Rico Henry\", \"Igor Thiago Nascimento Rodrigues\",\n",
        "        \"Solomon March\", \"Bart Verbruggen\", \"Reece James\", \"Matheus Franca de Oliveira\",\n",
        "        \"Youssef Ramalho Chermiti\", \"Nathan Patterson\", \"Jarrad Branthwaite\",\n",
        "        \"James Garner\", \"Seamus Coleman\", \"Ashley Young\", \"James Tarkowski\",\n",
        "        \"Bamidele Alli\", \"Harry Clarke\", \"George Hirst\", \"Nathan Broadhead\",\n",
        "        \"Wesley Burns\", \"Kalvin Phillips\", \"Janoi Donacien\", \"Patson Daka\",\n",
        "        \"Conor Coady\", \"Oscar Bobb\", \"Leny Yoro\", \"Tyrell Malacia\", \"Will Fish\",\n",
        "        \"Victor Lindelof\", \"Luke Shaw\", \"Rasmus Winther Hojlund\", \"Sven Botman\",\n",
        "        \"Jamaal Lascelles\", \"Lewis Miley\", \"Fabian Schar\", \"Sandro Tonali\",\n",
        "        \"Callum Wilson\", \"Danilo dos Santos de Oliveira\", \"Gavin Bazunu\",\n",
        "        \"Juan Larios\", \"Dominic Solanke\", \"Rodrigo Bentancur\", \"Nelson Semedo\",\n",
        "        \"Enso Gonzalez Medina\", \"Leon Chiwone\", \"Sasa Kalajdzic\",\"Jarell Quansah\"\n",
        "]\n",
        "\n",
        "# calling func fro printing team\n",
        "key_players = ['Erling Haaland']\n",
        "best_team = greedy_select_team(predicted_data, unavailable_players)\n",
        "best_team\n"
      ],
      "metadata": {
        "id": "j2XaIaiyPm_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz21XeC1Yylk"
      },
      "outputs": [],
      "source": [
        "#cross-validation in case\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def evaluate_model_with_cv(data, predictors):\n",
        "    X = data[predictors]\n",
        "    y = data['total_points_rolling']\n",
        "\n",
        "    model = GradientBoostingRegressor()\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "    print(f'Cross-Validated MSE: {-scores.mean()}')\n",
        "    print(f'Cross-Validated MAE: {-cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\").mean()}')\n",
        "    print(f'Cross-Validated R² Score: {cross_val_score(model, X, y, cv=5, scoring=\"r2\").mean()}')\n",
        "\n",
        "evaluate_model_with_cv(players_rolling, new_cols)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}